BASE_TASK_CONFIG_PATH: habitat_extensions/config/vlnce_t.yaml
TRAINER_NAME: dagger_evoenc # dagger, or recollect_trainer
DEBUG: False
SIMULATOR_GPU_ID: 0 # new version
TORCH_GPU_ID: 0
NUM_ENVIRONMENTS: 8
TENSORBOARD_DIR: data/tensorboard_dirs/evoenc_s2_tune
CHECKPOINT_FOLDER: data/checkpoints/evoenc_s2_tune
EVAL_CKPT_PATH_DIR: data/checkpoints/evoenc_s2_tune
RESULTS_DIR: data/checkpoints/evoenc_s2_tune/evals
ENVIRONMENT:
  MAX_EPISODE_STEPS: 250
EVAL:
  USE_CKPT_CONFIG: False
  SPLIT: val_unseen
  EPISODE_COUNT: -1

IL:
  epochs: 4
  batch_size: 1
  lr: 5.0e-5
  use_iw: True
  RECOLLECT_TRAINER:
    gt_file:
      data/datasets/R2R_VLNCE_NRSub_T/{split}/{split}_gt.json.gz
  load_from_ckpt: True
  load_from_pretrain: True
  ckpt_to_load: data/checkpoints/evoenc_s2/ckpt.EEPolicy.epoch0.pth
  
  DAGGER:
    iterations: 10
    update_size: 5000
    p: 0.75
    preload_lmdb_features: False
    lmdb_features_dir: data/trajectories_dirs/evoenc_s2_tune/trajectories.lmdb

MODEL:
  policy_name: EEPolicy

  PROGRESS_MONITOR:
    use: True
    alpha: 1.0
  EVOENC:
    layers: 4
    dropout: 0.0
    inner_dropout: 0.1
